# üöÄ User-data-IaC

[![Terraform](https://img.shields.io/badge/Terraform-1.5.7+-623CE4?logo=terraform&logoColor=white)](https://www.terraform.io/)
[![AWS](https://img.shields.io/badge/AWS-EKS-FF9900?logo=amazon-aws&logoColor=white)](https://aws.amazon.com/eks/)
[![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-CI/CD-2088FF?logo=github-actions&logoColor=white)](https://github.com/features/actions)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

Infrastructure as Code for deploying AWS EKS cluster with VPC using Terraform and GitHub Actions. This project provides a production-ready, secure, and cost-optimized EKS deployment with automated CI/CD pipeline.

## üìÅ Project Structure

```
User-data-IaC/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ eks-setup.yml          # GitHub Actions CI/CD pipeline
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ eks/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf                # EKS cluster, node groups, addons
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variable.tf            # EKS module variables
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ output.tf              # EKS module outputs
‚îÇ   ‚îî‚îÄ‚îÄ vpc/
‚îÇ       ‚îú‚îÄ‚îÄ main.tf                # VPC, subnets, gateways, routes
‚îÇ       ‚îú‚îÄ‚îÄ variable.tf            # VPC module variables
‚îÇ       ‚îî‚îÄ‚îÄ output.tf              # VPC module outputs
‚îú‚îÄ‚îÄ main.tf                        # Root module configuration
‚îú‚îÄ‚îÄ provider.tf                    # Terraform and AWS provider config
‚îú‚îÄ‚îÄ variable.tf                    # Root variables with defaults
‚îú‚îÄ‚îÄ output.tf                      # Root outputs
‚îú‚îÄ‚îÄ .gitignore                     # Git ignore patterns
‚îú‚îÄ‚îÄ .terraform.lock.hcl            # Terraform dependency lock
‚îú‚îÄ‚îÄ LICENSE                        # MIT License
‚îî‚îÄ‚îÄ README.md                      # This file give the brief of proj.
```

## üèóÔ∏è Architecture Overview

### Infrastructure Components

- **üåê VPC Module**: Creates isolated network with public/private subnets across 2 AZs as HA
- **‚ò∏Ô∏è EKS Module**: Deploys managed Kubernetes cluster with worker nodes and essential addons
- **üîÑ GitHub Actions**: Automated deployment pipeline with proper error handling
- **üîí Security**: IAM roles, access entries, and encrypted state management

### Network Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        VPC (10.0.0.0/16)                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ    us-east-1a           ‚îÇ           us-east-1b              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Public Subnet           ‚îÇ Public Subnet                     ‚îÇ
‚îÇ 10.0.3.0/24             ‚îÇ 10.0.4.0/24                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ   NAT Gateway       ‚îÇ ‚îÇ ‚îÇ        NAT Gateway              ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Private Subnet          ‚îÇ Private Subnet                    ‚îÇ
‚îÇ 10.0.1.0/24             ‚îÇ 10.0.2.0/24                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ  EKS Worker Nodes   ‚îÇ ‚îÇ ‚îÇ     EKS Worker Nodes            ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Quick Start

### Prerequisites

- [AWS CLI](https://aws.amazon.com/cli/) configured with appropriate permissions
- [Terraform](https://www.terraform.io/downloads.html) >= 1.5.7
- GitHub repository with Actions enabled
- S3 bucket for Terraform state storage
- DynamoDB table for state locking

### 1. Clone Repository

```bash
git clone https://github.com/your-username/User-data-IaC.git
cd User-data-IaC
```

### 2. Configure GitHub Secrets

Navigate to your repository ‚Üí Settings ‚Üí Secrets and variables ‚Üí Actions, and add:

| Secret Name | Description | Example |
|-------------|-------------|---------|
| `AWS_ACCESS_KEY_ID` | AWS Access Key | `AKIAIOSFODNN7EXAMPLE` |
| `AWS_SECRET_ACCESS_KEY` | AWS Secret Key | `wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY` |
| `BUCKET_TF_STATE` | S3 bucket for state | `my-terraform-state-bucket` |

### 3. Deploy Infrastructure

#### Option A: GitHub Actions (Recommended)
1. Go to **Actions** tab in your repository
2. Select **eks_setup** workflow
3. Click **Run workflow**
4. Choose **create-cluster** action and required **branch**

#### Option B: Local Deployment
```bash
# Initialize Terraform
terraform init -backend-config="bucket=your-terraform-state-bucket"

# Plan deployment
terraform plan

# Apply changes
terraform apply
```

### 4. Access Your Cluster

```bash
# Update kubeconfig
aws eks update-kubeconfig --region us-east-1 --name custom-eks

# Verify connection
kubectl get nodes
```

## ‚öôÔ∏è Configuration

### Default Configuration

| Component | Default Value | Description |
|-----------|---------------|-------------|
| **Region** | `us-east-1` | AWS region |
| **VPC CIDR** | `10.0.0.0/16` | VPC IP range |
| **EKS Version** | `1.33` | Kubernetes version |
| **Node Instance** | `t3.small` | EC2 instance type |
| **Node Count** | `2` (min: 2, max: 3) | Worker nodes |
| **Disk Size** | `20 GB` | EBS volume size |

### Customization

Create `terraform.tfvars` file:

```hcl
# Network Configuration
vpc_cidr = "10.0.0.0/16"
private_subnet_cidrs = ["10.0.1.0/24", "10.0.2.0/24"]
public_subnet_cidrs = ["10.0.3.0/24", "10.0.4.0/24"]
availability_zones = ["us-east-1a", "us-east-1b"]

# EKS Configuration
cluster_version = "1.33"
node_groups = {
  general = {
    instance_types = ["t3.small"]
    scaling_config = {
      desired_capacity = 3
      min_size         = 2
      max_size         = 5
    }
  }
}
```

## üì¶ Resources Created

### VPC Module Resources
- ‚úÖ 1 VPC with DNS support
- ‚úÖ 2 Public subnets (multi-AZ)
- ‚úÖ 2 Private subnets (multi-AZ)
- ‚úÖ 1 Internet Gateway
- ‚úÖ 2 NAT Gateways (high availability)
- ‚úÖ Route tables and associations
- ‚úÖ Elastic IPs for NAT Gateways

### EKS Module Resources
- ‚úÖ EKS Cluster with API endpoint
- ‚úÖ Managed node group with auto-scaling
- ‚úÖ Essential addons (VPC CNI, kube-proxy, CoreDNS, EBS CSI)
- ‚úÖ IAM roles and policies
- ‚úÖ Access entries for cluster management
- ‚úÖ Security groups (managed by EKS)

## üîí Security Features

- **üîê Private Worker Nodes**: All worker nodes in private subnets
- **üõ°Ô∏è IAM Access Control**: Proper IAM roles and policies
- **üîë Access Entries**: Modern EKS access management
- **üóÑÔ∏è Encrypted State**: S3 backend with encryption
- **üîí State Locking**: DynamoDB prevents concurrent modifications
- **üìã Least Privilege**: Minimal required permissions

## üí∞ Cost Optimization

- **üí° Right-sized Instances**: t3.small for development workloads
- **üìà Auto Scaling**: Automatic node scaling based on demand
- **üåê Managed Services**: Reduces operational overhead
- **‚ö° Spot Instances**: Can be configured for non-production workloads

### Estimated Monthly Costs (us-east-1)
- EKS Cluster: ~$73/month
- 2x t3.small nodes: ~$30/month
- 2x NAT Gateways: ~$90/month
- **Total**: ~$193/month

> üí° **Cost Tip**: Use single NAT Gateway for development to save ~$45/month

## üîß Advanced Configuration

### Adding Spot Instances

```hcl
node_groups = {
  spot = {
    instance_types = ["t3.medium", "t3.large"]
    capacity_type  = "SPOT"
    scaling_config = {
      desired_capacity = 1
      min_size         = 1
      max_size         = 10
    }
  }
}
```

### Custom Addons

```hcl
# Add AWS Load Balancer Controller
resource "aws_eks_addon" "aws_load_balancer_controller" {
  cluster_name = aws_eks_cluster.custom.name
  addon_name   = "aws-load-balancer-controller"
}
```

## üîç Monitoring & Observability

### CloudWatch Integration
```bash
# Enable CloudWatch logging
aws eks update-cluster-config \
  --name custom-eks \
  --logging '{"enable":["api","audit","authenticator","controllerManager","scheduler"]}'
```

### Useful Commands

```bash
# Check cluster status
kubectl get nodes -o wide

# View system pods
kubectl get pods -n kube-system

# Check addon status
aws eks describe-addon --cluster-name custom-eks --addon-name vpc-cni
```

### Testing / accesssing application

After deploying application in eks, to access it from service as NodePort in case of LoadBalancer use the below steps:
(If deployed as LB service then we can access application using the DNS provided by LB)

Start a debug pod with curl installed
Run a temporary pod with curl tool (example uses curlimages/curl image):

kubectl run -i --tty curlpod --image=curlimages/curl --restart=Never -- sh

This gives you a shell prompt inside the pod.
Curl your service inside cluster
Use the service name and port, for example:

curl http://backend-service.myapp.svc.cluster.local:8008/docs

O/P would be the HTTP in CLI which confirms the app running.

## üö® Troubleshooting

### Common Issues

| Issue | Solution |
|-------|----------|
| **Access Denied** | Verify IAM permissions and access entries |
| **Timeout Errors** | Check VPC configuration and security groups |
|**EBS not Bounding**| When the pvc is applied it usually will be in pending state due to missing permission |
| **State Lock** | Verify DynamoDB table exists and is accessible |
| **Node Join Issues** | Check subnet routing and security groups |

### Debug Commands

```bash
# Check AWS credentials
aws sts get-caller-identity

# Verify EKS cluster
aws eks describe-cluster --name custom-eks

# Check node group status
aws eks describe-nodegroup --cluster-name custom-eks --nodegroup-name general
```

## üßπ Cleanup

### Via GitHub Actions
1. Go to **Actions** tab
2. Run **eks_setup** workflow
3. Select **delete-cluster** action

### Via CLI
```bash
terraform destroy
```

## üìö Additional Resources

### Official Documentation
- [AWS EKS User Guide](https://docs.aws.amazon.com/eks/latest/userguide/)
- [Terraform AWS Provider](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)
- [Kubernetes Documentation](https://kubernetes.io/docs/)

### Best Practices
- [EKS Best Practices Guide](https://aws.github.io/aws-eks-best-practices/)
- [Terraform Best Practices](https://www.terraform-best-practices.com/)
- [AWS Well-Architected Framework](https://aws.amazon.com/architecture/well-architected/)

### Tools & Extensions
- [kubectl](https://kubernetes.io/docs/tasks/tools/) - Kubernetes CLI
- [eksctl](https://eksctl.io/) - EKS CLI tool
- [k9s](https://k9scli.io/) - Terminal UI for Kubernetes
- [Lens](https://k8slens.dev/) - Kubernetes IDE
- [minikube](https://minikube.sigs.k8s.io/docs/) - Running k8s locally 

### Community
- [AWS EKS Roadmap](https://github.com/aws/containers-roadmap)
- [Terraform Community](https://discuss.hashicorp.com/c/terraform-core/)
- [Kubernetes Slack](https://kubernetes.slack.com/)

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôã‚Äç‚ôÇÔ∏è Support

- üìß Email: sudarshanrpgowda7@gmail.com
- üêõ Issues: [GitHub Issues](https://github.com/sudarshan-rp/User-data-IaC/issues)
- üí¨ Discussions: [GitHub Discussions](https://github.com/sudarshan-rp/User-data-IaC/discussions)

---

‚≠ê **Star this repository if it helped you!**
